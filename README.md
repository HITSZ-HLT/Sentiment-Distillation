# Targeted Distillation for Sentiment Analysis

This repository contains the official datasets, and evaluation scripts for the paper:

**Targeted Distillation for Sentiment Analysis**
*Yice Zhang, Guangyu Xie, Jingjie Lin, Jianzhu Bao, Qianlong Wang, Xi Zeng, Ruifeng Xu (2025)*[[arXiv]](https://arxiv.org/abs/2503.03225)

Our work introduces a **targeted distillation framework** designed to transfer sentiment-related capabilities from advanced LLMs into compact language models. The project also provides **SentiBench**, a comprehensive benchmark for evaluating sentiment-analysis performance across diverse task types.

---

## ğŸš€ Abstract

This paper explores targeted distillation methods for sentiment analysis, aiming to build compact and practical models that preserve strong and generalizable sentiment analysis capabilities. To this end, we conceptually decouple the distillation target into knowledge and alignment and accordingly propose a two-stage distillation framework. Moreover, we introduce SentiBench, a comprehensive and systematic sentiment analysis benchmark that covers a diverse set of tasks across 12 datasets. We evaluate a wide range of models on this benchmark. Experimental results show that our approach substantially enhances the performance of compact models across diverse sentiment analysis tasks, and the resulting models demonstrate strong generalization to unseen tasks, showcasing robust competitiveness against existing small-scale models.


## ğŸ“Š SentiBench Benchmark

We introduce **SentiBench**, a sentiment analysis benchmark covering:

* **3 Task Categories**
* **12 Datasets**
* Including basic sentiment analysis, multifaceted sentiment analysis, and fine-grained sentiment analysis.

![alt text](./img/statistic.jpg)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ bash/                         # Evaluation scripts
â”‚   â”œâ”€â”€ fsa.sh
â”‚   â”œâ”€â”€ multifaced.sh
â”‚   â”œâ”€â”€ multi_task_fsa.sh
â”‚   â””â”€â”€ multi_task_multifaced.sh
â”œâ”€â”€ datasets/                     # SentiBench datasets
â”‚   â”œâ”€â”€ absa/                     # Fine-grained sentiment analysis (FSA)
â”‚   â”œâ”€â”€ multifaced/               # Multi-faceted sentiment analysis (MSA)
â”‚   â””â”€â”€ sc/                       # Basic sentiment analysis (BSA)
â”œâ”€â”€ fsa.py                        # FSA evaluation entry
â”œâ”€â”€ icl_multifaced.py             # MFSA evaluation entry
â”œâ”€â”€ model_name.json               # Model version-to-path mapping
â”œâ”€â”€ model_weights/                # Downloaded distilled models
â”‚   â”œâ”€â”€ llama-3-1B-sentiment-distillation-v1
â”‚   â”œâ”€â”€ llama-3-3B-sentiment-distillation-v1
â”‚   â””â”€â”€ Qwen2.5-1.5B-sentiment-distillation-v1
â”œâ”€â”€ output/
â”‚   â””â”€â”€ result.txt                # Final results
â”œâ”€â”€ parse.py                      # Result parser
â”œâ”€â”€ parse_utils/                  # Parsing utilities for different tasks
â”‚   â”œâ”€â”€ acsa.py
â”‚   â”œâ”€â”€ asqp.py
â”‚   â”œâ”€â”€ atsa.py
â”‚   â”œâ”€â”€ coqe.py
â”‚   â”œâ”€â”€ multifaced.py
â”‚   â””â”€â”€ ssa.py
â”œâ”€â”€ utils.py
â””â”€â”€ README.md
```

---


## **Training Corpus**

Our targeted distillation corpus: [https://huggingface.co/datasets/zhang-yice/sentiment-distillation-v1](https://huggingface.co/datasets/zhang-yice/sentiment-distillation-v1)

### **Released Distilled Models**

| Model                                  | Base Model   | HuggingFace                                                                                                                                          |
| -------------------------------------- | ------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| llama-3-1B-sentiment-distillation-v1   | Llama-3-1B-Instruct   | [https://huggingface.co/zhang-yice/llama-3-1B-sentiment-distillation-v1](https://huggingface.co/zhang-yice/llama-3-1B-sentiment-distillation-v1)     |
| Qwen2.5-1.5B-sentiment-distillation-v1 | Qwen2.5-1.5B-Instruct | [https://huggingface.co/zhang-yice/Qwen2.5-1.5B-sentiment-distillation-v1](https://huggingface.co/zhang-yice/Qwen2.5-1.5B-sentiment-distillation-v1) |
| llama-3-3B-sentiment-distillation-v1   | Llama-3-3B-Instruct   | [https://huggingface.co/zhang-yice/llama-3-3B-sentiment-distillation-v1](https://huggingface.co/zhang-yice/llama-3-3B-sentiment-distillation-v1)     |

Download the corresponding model and place it into:

```
./model_weights/{model_name}
```

---

## ğŸ§ª Evaluation

### 1ï¸âƒ£ Download distilled models

Download the distilled model from huggingface and place each model under:

```
model_weights/
    â”œâ”€â”€ Qwen2.5-1.5B-sentiment-distillation-v1/
    â”œâ”€â”€ llama-3-1B-sentiment-distillation-v1/
    â””â”€â”€ llama-3-3B-sentiment-distillation-v1/
```

Ensure `model_name.json` correctly maps the model version to its path.

---

### 2ï¸âƒ£ Run Evaluation on SentiBench

#### **Qwen2.5-1.5B-sentiment-distillation-v1**

```bash
# Fine-grained Sentiment Analysis (FSA) 
bash/multi_task_fsa.sh -c 0 -b Qwen2.5-1.5B-sentiment-distillation-v1 -v Qwen2.5-1.5B-sentiment-distillation-v1 -z 16

# Multi-faceted Sentiment (MSA) + Basic Sentiment Analysis (BSA)
bash/multi_task_multifaced.sh -c 1 -b Qwen2.5-1.5B-sentiment-distillation-v1 -v Qwen2.5-1.5B-sentiment-distillation-v1
```

#### **llama-3-1B-sentiment-distillation-v1**

```bash
bash/multi_task_fsa.sh -c 0 -b llama-3-1B-sentiment-distillation-v1 -v llama-3-1B-sentiment-distillation-v1 -z 16
bash/multi_task_multifaced.sh -c 1 -b llama-3-1B-sentiment-distillation-v1 -v llama-3-1B-sentiment-distillation-v1
```

#### **llama-3-3B-sentiment-distillation-v1**

```bash
bash/multi_task_fsa.sh -c 0 -b llama-3-3B-sentiment-distillation-v1 -v llama-3-3B-sentiment-distillation-v1 -z 16
bash/multi_task_multifaced.sh -c 1 -b llama-3-3B-sentiment-distillation-v1 -v llama-3-3B-sentiment-distillation-v1
```

---

### 3ï¸âƒ£ Parse Evaluation Results

```bash
python parse.py
```

Detailed results will appear in:

```
output/result.txt
```

---

## ğŸ“„ Citation

If you use our code, datasets, or models, please cite:

```bibtex
@inproceedings{zhang-etal-2025-targeted,
    title = "Targeted Distillation for Sentiment Analysis",
    author = "Zhang, Yice  and
      Xie, Guangyu  and
      Lin, Jingjie  and
      Bao, Jianzhu  and
      Wang, Qianlong  and
      Zeng, Xi  and
      Xu, Ruifeng",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.emnlp-main.1127/",
    doi = "10.18653/v1/2025.emnlp-main.1127",
    pages = "22169--22192",
    ISBN = "979-8-89176-332-6",
}
```